{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloader Middlewares（下载器中间件）\n",
    "   \n",
    "- 下载器中间件引擎和下载器之间通信的中间件。在这个中间件中我们可以设置代理、跟换请求头等来达到反反爬虫的目的。要写下载器中间件，可以在下载器中实现两个方法：\n",
    "    - process_request(self,request,spider)：这个方法是在请求发送前会执行；\n",
    "    - process_response(self,request,response,spider)：这个方法是数据下载到引擎之前执行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process_request(self,request,spider)\n",
    "这个方法是下载器在发送请求之前会执行的。一般可以在这个里面设置随机代理ip等。\n",
    "  1. 参数：\n",
    "    - request：发送请求的request对象。\n",
    "    - spider：发送请求的spider对象。\n",
    "  2. 返回值：\n",
    "    - 返回None：如果返回None，Scrapy将继续处理该request，执行其他中间件中的相应方法，直到合适的下载器处理函数被调用。\n",
    "    - 返回Response对象：Scrapy将不会调用任何其他的process_request方法，将直接返回这个response对象。已经激活的中间件process_response()方法则会在每个response返回时调用。\n",
    "    - 返回Request对象：不再使用之前的request对象去下载数据，而是根据现在返回的request对象返回数据。\n",
    "    - 如果这个方法中抛出了异常，则会调用process_exception方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process_response(self,request,response,spider)\n",
    "这个是下载器下载的数据到引擎中间会执行的方法。\n",
    "  1. 参数：\n",
    "      - request：request对象。\n",
    "      - response：被处理的response对象。\n",
    "      - spider：spider对象。\n",
    "  2. 返回值：\n",
    "      - 返回Response对象：会将这个新的response对象传给其他中间件，最终传给爬虫。\n",
    "      - 返回Request对象：下载器连接切断，返回的request会重新被下载器调度下载。\n",
    "      - 如果抛出一个异常，那么调用request的errback方法，如果没有指定这个方法，那么会抛出一个异常。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 中间件(DownloaderMiddlewares)\n",
    "    - 中间件是处于引擎和下载器中间的一层组件\n",
    "    - 可以有很多个，被按顺序加载执行\n",
    "    - 作用是对发出的请求和返回的结果进行预处理\n",
    "    - 在middlewares文件中\n",
    "    - 需要在settings中设置以便生效\n",
    "    - 一般一个中间件完成一项功能\n",
    "    - 必须实现以下一个或者多个方法\n",
    "        - process_request(self, request, spider)\n",
    "            - 在request通过的时候被调用\n",
    "            - 必须返回None或Response或Request或raise IgnoreRequest\n",
    "            - None: scrapy将继续处理该request\n",
    "            - Request： scrapy会停止调用process_request并冲洗调度返回的reqeust\n",
    "            - Response： scrapy不会调用其他的process_request或者process_exception，直接讲该response作为结果返回 同时会调用process_response函数\n",
    "        - process_response(self, request, response, spider)\n",
    "            - 跟process_request大同小异\n",
    "            - 每次返回结果的时候会自动调用\n",
    "            - 可以有多个，按顺序调用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 随机请求头中间件：\n",
    "爬虫在频繁访问一个页面的时候，这个请求头如果一直保持一致，那么容易被服务器发现，从而禁止掉这个请求头的访问。因此我们要在访问这个页面之前随机的更改请求头，这样才可以避免爬虫被抓。   \n",
    "随机更改请求头，可以在下载器中间件中实现。在请求发送给服务器之前，随机的选择一个请求头。这样可以避免总使用一个请求了。   \n",
    "   \n",
    "示例代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UserAgenDownloadMiddleware(object):\n",
    "    USER_AGENTS = {\n",
    "        'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.121 Safari/537.36',\n",
    "        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "        'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.133 Safari/534.16',\n",
    "        'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2',\n",
    "        'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:34.0) Gecko/20100101 Firefox/34.0',\n",
    "        'Mozilla/5.0 (X11; U; Linux x86_64; zh-CN; rv:1.9.2.10) Gecko/20100922 Ubuntu/10.10 (maverick) Firefox/3.6.10'\n",
    "    }\n",
    "    def process_request(self,request,spider):\n",
    "        user_agent = random.choice(self.USER_AGENTS)    # 从USER_AGENTS列表中随机选择一个User-Agent\n",
    "        request.headers['User-Agent'] = user_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ip代理池中间件\n",
    "   \n",
    "### 购买代理：\n",
    "在以下代理商购买代理：\n",
    "1. 芝麻代理：http://www.zhimaruanjian.com/\n",
    "2. 太阳代理：http://www.taiyangruanjian.com/\n",
    "3. 快代理：https://www.kuaidaili.com/\n",
    "4. 讯代理：http://www.xdaili.cn/\n",
    "5. 蚂蚁代理：http://www.mayidaili.com/\n",
    "等等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用ip代理池：\n",
    "示例代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ip代理池中间件\n",
    "################# 开放代理写法 #################\n",
    "class IPProxyDownloadMiddleware(object):\n",
    "    PROXIES = [\"163.125.115.189:8118\", \"118.122.114.236:9000\", \"117.90.252.146:9000\", \"123.101.207.205:9999\", \"211.159.171.58:80\", \"49.86.180.212:9999\"]\n",
    "\n",
    "    def process_request(self, request, spider):\n",
    "        proxy = random.choice(self.PROXIES)\n",
    "        print(\"被选中的代理：%s\" % proxy)\n",
    "#         request.meta['proxy'] = proxy\n",
    "        request.meta['proxy'] = \"http://\" + proxy\n",
    "\n",
    "################# 带用户名和密码的私享代理用法（需要设置请求头） #################\n",
    "class IPProxyDownloadMiddleware(object):\n",
    "    def process_request(self, request, spider):\n",
    "        proxy = \"121.199.6.124:16816\"\n",
    "        user_password = \"970138074:rcdj35ur\"\n",
    "        request.meta['proxy'] = proxy\n",
    "        # bytes\n",
    "        b64_user_password = base64.b64encode(user_password.encode('utf-8'))\n",
    "        request.headers['Proxy-Authorization'] = 'Basic ' + b64_user_password.decode('utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
