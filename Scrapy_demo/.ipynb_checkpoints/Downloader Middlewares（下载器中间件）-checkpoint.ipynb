{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloader Middlewares（下载器中间件）\n",
    "   \n",
    "- 下载器中间件引擎和下载器之间通信的中间件。在这个中间件中我们可以设置代理、跟换请求头等来达到反反爬虫的目的。要写下载器中间件，可以在下载器中实现两个方法：\n",
    "    - process_request(self,request,spider)：这个方法是在请求发送前会执行；\n",
    "    - process_response(self,request,response,spider)：这个方法是数据下载到引擎之前执行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process_request(self,request,spider)\n",
    "这个方法是下载器在发送请求之前会执行的。一般可以在这个里面设置随机代理ip等。\n",
    "  1. 参数：\n",
    "    - request：发送请求的request对象。\n",
    "    - spider：发送请求的spider对象。\n",
    "  2. 返回值：\n",
    "    - 返回None：如果返回None，Scrapy将继续处理该request，执行其他中间件中的相应方法，直到合适的下载器处理函数被调用。\n",
    "    - 返回Response对象：Scrapy将不会调用任何其他的process_request方法，将直接返回这个response对象。已经激活的中间件process_response()方法则会在每个response返回时调用。\n",
    "    - 返回Request对象：不再使用之前的request对象去下载数据，而是根据现在返回的request对象返回数据。\n",
    "    - 如果这个方法中抛出了异常，则会调用process_exception方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process_response(self,request,response,spider)\n",
    "这个是下载器下载的数据到引擎中间会执行的方法。\n",
    "  1. 参数：\n",
    "      - request：request对象。\n",
    "      - response：被处理的response对象。\n",
    "      - spider：spider对象。\n",
    "  2. 返回值：\n",
    "      - 返回Response对象：会将这个新的response对象传给其他中间件，最终传给爬虫。\n",
    "      - 返回Request对象：下载器连接切断，返回的request会重新被下载器调度下载。\n",
    "      - 如果抛出一个异常，那么调用request的errback方法，如果没有指定这个方法，那么会抛出一个异常。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 中间件(DownloaderMiddlewares)\n",
    "    - 中间件是处于引擎和下载器中间的一层组件\n",
    "    - 可以有很多个，被按顺序加载执行\n",
    "    - 作用是对发出的请求和返回的结果进行预处理\n",
    "    - 在middlewares文件中\n",
    "    - 需要在settings中设置以便生效\n",
    "    - 一般一个中间件完成一项功能\n",
    "    - 必须实现以下一个或者多个方法\n",
    "        - process_request(self, request, spider)\n",
    "            - 在request通过的时候被调用\n",
    "            - 必须返回None或Response或Request或raise IgnoreRequest\n",
    "            - None: scrapy将继续处理该request\n",
    "            - Request： scrapy会停止调用process_request并冲洗调度返回的reqeust\n",
    "            - Response： scrapy不会调用其他的process_request或者process_exception，直接讲该response作为结果返回 同时会调用process_response函数\n",
    "        - process_response(self, request, response, spider)\n",
    "            - 跟process_request大同小异\n",
    "            - 每次返回结果的时候会自动调用\n",
    "            - 可以有多个，按顺序调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
